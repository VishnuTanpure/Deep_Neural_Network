{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ZX_Or9iiKP",
   "metadata": {
    "id": "13ZX_Or9iiKP"
   },
   "source": [
    "# $\\color{red}{Deep \\ \\ Neural \\ \\ Network \\ \\ on \\ \\ MNIST \\ \\ Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ps1sh4uygIEs",
   "metadata": {
    "id": "Ps1sh4uygIEs"
   },
   "source": [
    "# $Training \\ \\ Data$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RHxkFAjhgaLa",
   "metadata": {
    "id": "RHxkFAjhgaLa"
   },
   "source": [
    "## $Import \\ \\ Basic \\ \\ Libraries$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb21dd53-96c0-4e5b-8ca4-ce051806a37f",
   "metadata": {
    "id": "eb21dd53-96c0-4e5b-8ca4-ce051806a37f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # For handling and analyzing structured data\n",
    "import numpy as np  # For numerical operations and array handling\n",
    "from matplotlib import pyplot as plt  # For data visualization and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PqzMY6Pbgf5y",
   "metadata": {
    "id": "PqzMY6Pbgf5y"
   },
   "source": [
    "## $Import \\ \\ Training \\ \\ Data$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4933a4-19e2-4156-851b-f08d36492591",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "3d4933a4-19e2-4156-851b-f08d36492591",
    "outputId": "f6d5aa7f-e9b2-4a54-91c3-338d96d1c628"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")  # Load the dataset from a CSV file into a DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75df7ad7-e1ac-4889-9b3d-a3f34e9d660e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75df7ad7-e1ac-4889-9b3d-a3f34e9d660e",
    "outputId": "e276289e-4845-4bbe-f37e-8b92149051b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Examples : 42000\n",
      "No. of Features(Pixels) : 785\n"
     ]
    }
   ],
   "source": [
    "data = np.array(df)  # Convert the DataFrame into a NumPy array for easier manipulation\n",
    "m, n = df.shape\n",
    "print(\"No. of Examples :\", m)\n",
    "print(\"No. of Features(Pixels) :\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KCys-7U7gnhE",
   "metadata": {
    "id": "KCys-7U7gnhE"
   },
   "source": [
    "## $Data \\ \\ Modeling$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280038be-985a-4bae-af36-8ee459072e3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "280038be-985a-4bae-af36-8ee459072e3f",
    "outputId": "89e5546a-9a5c-46ea-f852-5b4fefd570e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples : 33600\n",
      "X_train Shape : (784, 33600)\n",
      "Y_train Shape : (33600,)\n",
      "\n",
      "No. of testing examples : 8400\n",
      "X_test Shape : (784, 8400)\n",
      "Y_test Shape : (8400,)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)  # Shuffle the data to ensure randomness\n",
    "m_train = int(m * 0.8)  # Use 80% of the data for training\n",
    "print(\"No. of training examples :\", m_train)\n",
    "\n",
    "# Split training data and transpose for easier manipulation\n",
    "train_data = data[0:m_train].T  # Transpose train data\n",
    "X_train = train_data[1:n]  # Extract features (all rows except the first)\n",
    "X_train = X_train / 255  # Normalize feature values to [0, 1]\n",
    "Y_train = train_data[0]  # Extract labels (first row)\n",
    "print(\"X_train Shape :\", X_train.shape)\n",
    "print(\"Y_train Shape :\", Y_train.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "# Prepare test data (remaining 20%)\n",
    "print(\"No. of testing examples :\", m - m_train)\n",
    "test_data = data[m_train:].T  # Transpose test data\n",
    "X_test = test_data[1:n]  # Extract test features\n",
    "X_test = X_test / 255  # Normalize test features\n",
    "Y_test = test_data[0]  # Extract test labels\n",
    "print(\"X_test Shape :\", X_test.shape)\n",
    "print(\"Y_test Shape :\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o87rvMyQcQAP",
   "metadata": {
    "id": "o87rvMyQcQAP"
   },
   "source": [
    "# $Weights \\ \\ \\& \\ \\ Biases$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3KFYYiTjhYNB",
   "metadata": {
    "id": "3KFYYiTjhYNB"
   },
   "source": [
    "## $Initiate \\ \\ Weights \\ \\ \\& \\ \\ Biases$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe1cbc7-8d11-4783-9095-2d47d3e13748",
   "metadata": {
    "id": "cfe1cbc7-8d11-4783-9095-2d47d3e13748"
   },
   "outputs": [],
   "source": [
    "# Initialize Weights and Biases\n",
    "def initialize_weights_biases(layers_dims):\n",
    "    \"\"\"\n",
    "    Initializes weights and biases for each layer in the network.\n",
    "    Args:\n",
    "        layers_dims (list): List specifying the number of neurons in each layer.\n",
    "    Returns:\n",
    "        dict: Dictionary containing initialized weights and biases.\n",
    "    \"\"\"\n",
    "    np.random.seed(1)  # Seed for reproducibility\n",
    "    weights_biases = {}\n",
    "    L = len(layers_dims)  # Number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        # Initialization for weights to maintain gradient flow\n",
    "        weights_biases['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) / np.sqrt(layers_dims[l-1])\n",
    "        # Initialize biases as zeros\n",
    "        weights_biases['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\n",
    "    return weights_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iHXdUoJ4cbVA",
   "metadata": {
    "id": "iHXdUoJ4cbVA"
   },
   "source": [
    "# $Activation \\ \\ Functions$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cf6f33-de93-4269-912b-98c125c35a4f",
   "metadata": {
    "id": "f5cf6f33-de93-4269-912b-98c125c35a4f"
   },
   "outputs": [],
   "source": [
    "# ReLU activation function\n",
    "def ReLU(Z):\n",
    "    # Applies ReLU activation: sets negative values to 0, retains positive values\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "# Softmax activation function\n",
    "def softmax(Z):\n",
    "    # Applies softmax to convert logits into probabilities\n",
    "    A = np.exp(Z) / sum(np.exp(Z))  # Normalizes exponentials of inputs\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97b3d3-5b41-417d-b66c-8a4fad34e46c",
   "metadata": {},
   "source": [
    "# $Forward \\ \\ Propogation$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0844ec-c936-48b6-b678-e4ee4fdb7f1c",
   "metadata": {
    "id": "9c0844ec-c936-48b6-b678-e4ee4fdb7f1c"
   },
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "def forward_prop(weights_biases, X):\n",
    "    \"\"\"\n",
    "    Computes forward propagation through the network.\n",
    "    Args:\n",
    "        weights_biases (dict): Current weights and biases.\n",
    "        X (ndarray): Input data.\n",
    "    Returns:\n",
    "        dict: Activations and pre-activations for each layer.\n",
    "    \"\"\"\n",
    "    L = len(weights_biases) // 2  # Number of layers\n",
    "    LNLcaches = {\"A0\": X}  # Initialize cache to store activations and pre-activations\n",
    "\n",
    "    A = X  # Set input as initial activation\n",
    "    for l in range(1, L):\n",
    "        Z = weights_biases[\"W\" + str(l)].dot(A) + weights_biases[\"b\" + str(l)]  # Linear transformation\n",
    "        A = ReLU(Z)  # Apply ReLU activation for hidden layers\n",
    "        LNLcaches[\"Z\" + str(l)] = Z  # Store pre-activation\n",
    "        LNLcaches[\"A\" + str(l)] = A  # Store activation\n",
    "\n",
    "    # Compute output layer\n",
    "    Z = weights_biases[\"W\" + str(L)].dot(A) + weights_biases[\"b\" + str(L)]  # Linear transformation for output\n",
    "    A = softmax(Z)  # Apply softmax activation for output layer\n",
    "    LNLcaches[\"Z\" + str(L)] = Z  # Store pre-activation for output\n",
    "    LNLcaches[\"A\" + str(L)] = A  # Store final output activation\n",
    "\n",
    "    return LNLcaches  # Return all layer activations and pre-activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b779f5c-0471-4de2-b569-f66812bc913b",
   "metadata": {},
   "source": [
    "# $Cost$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dea8de7-ddd6-4930-b351-5b95b59a4c70",
   "metadata": {
    "id": "6dea8de7-ddd6-4930-b351-5b95b59a4c70"
   },
   "outputs": [],
   "source": [
    "# One-Hot encode target column\n",
    "def one_hot(Y):\n",
    "    \"\"\"\n",
    "    Converts target labels into one-hot encoded format.\n",
    "    Args:\n",
    "        Y (ndarray): Array of target labels.\n",
    "    Returns:\n",
    "        ndarray: One-hot encoded representation of Y.\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))  # Initialize a zero matrix of shape (num_samples, num_classes)\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1  # Set the corresponding class index to 1 for each sample\n",
    "    one_hot_Y = one_hot_Y.T  # Transpose to match expected shape (num_classes, num_samples)\n",
    "    return one_hot_Y\n",
    "\n",
    "# Cross-Entropy loss\n",
    "def compute_loss(AL, Y):\n",
    "    \"\"\"\n",
    "    Computes cross-entropy loss.\n",
    "    Args:\n",
    "        AL (ndarray): Output layer activations (softmax probabilities).\n",
    "        Y (ndarray): True labels.\n",
    "    Returns:\n",
    "        float: Cross-entropy loss.\n",
    "    \"\"\"\n",
    "    m = Y.size  # Number of examples\n",
    "    one_hot_Y = one_hot(Y)  # One-hot encode the true labels\n",
    "    loss = -np.sum(one_hot_Y * np.log(AL + 1e-8)) / m  # Compute cross-entropy loss with numerical stability (epsilon)\n",
    "    return loss  # Return the calculated loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4sppdYJEd0ZY",
   "metadata": {
    "id": "4sppdYJEd0ZY"
   },
   "source": [
    "# $Backward \\ \\ Propogation$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1ed85c8-5deb-4609-b6c0-4a9e26d7a8c9",
   "metadata": {
    "id": "b1ed85c8-5deb-4609-b6c0-4a9e26d7a8c9"
   },
   "outputs": [],
   "source": [
    "def deriv_ReLU(Z):\n",
    "    # Derivative of ReLU: 1 for positive values, 0 for negative values\n",
    "    return Z > 0\n",
    "\n",
    "def back_prop(LNLcaches, weights_biases, X, Y):\n",
    "    \"\"\"\n",
    "    Performs backpropagation to compute gradients of weights and biases.\n",
    "    Args:\n",
    "        LNLcaches (dict): Cache from forward propagation containing activations and pre-activations.\n",
    "        weights_biases (dict): Current weights and biases.\n",
    "        X (ndarray): Input data.\n",
    "        Y (ndarray): True labels.\n",
    "    Returns:\n",
    "        dict: Gradients for weights and biases.\n",
    "    \"\"\"\n",
    "    L = len(weights_biases) // 2  # Number of layers\n",
    "    m = Y.size  # Number of examples\n",
    "    one_hot_Y = one_hot(Y)  # Convert true labels to one-hot encoding\n",
    "    grads = {}  # Dictionary to store gradients\n",
    "\n",
    "    # Output layer gradients\n",
    "    dZL = LNLcaches[\"A\" + str(L)] - one_hot_Y  # Derivative of loss w.r.t. ZL\n",
    "    grads[\"dZ\" + str(L)] = dZL\n",
    "    dWL = 1 / m * dZL.dot(LNLcaches[\"A\" + str(L-1)].T)  # Gradient of weights for output layer\n",
    "    grads[\"dW\" + str(L)] = dWL\n",
    "    dbL = 1 / m * np.sum(dZL, axis=1).reshape(-1, 1)  # Gradient of biases for output layer\n",
    "    grads[\"db\" + str(L)] = dbL\n",
    "\n",
    "    # Gradients for hidden layers\n",
    "    for l in reversed(range(1, L)):\n",
    "        dZl = weights_biases[\"W\" + str(l + 1)].T.dot(grads[\"dZ\" + str(l + 1)]) * deriv_ReLU(LNLcaches[\"Z\" + str(l)])\n",
    "        grads[\"dZ\" + str(l)] = dZl\n",
    "        dWl = 1 / m * dZl.dot(LNLcaches[\"A\" + str(l-1)].T)  # Gradient of weights for layer l\n",
    "        grads[\"dW\" + str(l)] = dWl\n",
    "        dbl = 1 / m * np.sum(dZl, axis=1).reshape(-1, 1)  # Gradient of biases for layer l\n",
    "        grads[\"db\" + str(l)] = dbl\n",
    "\n",
    "    return grads  # Return computed gradients\n",
    "\n",
    "def update_params(weights_biases, grads, alpha):\n",
    "    \"\"\"\n",
    "    Updates weights and biases using gradient descent.\n",
    "    Args:\n",
    "        weights_biases (dict): Current weights and biases.\n",
    "        grads (dict): Gradients for weights and biases.\n",
    "        alpha (float): Learning rate.\n",
    "    Returns:\n",
    "        dict: Updated weights and biases.\n",
    "    \"\"\"\n",
    "    L = len(weights_biases) // 2  # Number of layers\n",
    "    for l in range(1, L + 1):\n",
    "        # Update weights and biases using gradients\n",
    "        weights_biases[\"W\" + str(l)] -= alpha * grads[\"dW\" + str(l)]\n",
    "        weights_biases[\"b\" + str(l)] -= alpha * grads[\"db\" + str(l)]\n",
    "\n",
    "    return weights_biases  # Return updated parameters\n",
    "\n",
    "def get_predictions(AL):\n",
    "    \"\"\"\n",
    "    Converts output probabilities into predicted labels.\n",
    "    Args:\n",
    "        AL (ndarray): Output probabilities from the softmax layer.\n",
    "    Returns:\n",
    "        ndarray: Predicted labels (class indices with highest probability).\n",
    "    \"\"\"\n",
    "    return np.argmax(AL, 0)  # Returns index of maximum probability for each example.\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    \"\"\"\n",
    "    Computes accuracy by comparing predictions to true labels.\n",
    "    Args:\n",
    "        predictions (ndarray): Predicted labels.\n",
    "        Y (ndarray): True labels.\n",
    "    Returns:\n",
    "        float: Accuracy as the proportion of correct predictions.\n",
    "    \"\"\"\n",
    "    return np.sum(predictions == Y) / Y.size  # Proportion of correct predictions.\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha, layers_dims):\n",
    "    \"\"\"\n",
    "    Trains the neural network using gradient descent.\n",
    "    Args:\n",
    "        X (ndarray): Input data.\n",
    "        Y (ndarray): True labels.\n",
    "        iterations (int): Number of training iterations.\n",
    "        alpha (float): Learning rate.\n",
    "        layers_dims (list): List specifying the number of neurons in each layer.\n",
    "    Returns:\n",
    "        dict: Trained weights and biases.\n",
    "    \"\"\"\n",
    "    weights_biases = initialize_weights_biases(layers_dims)  # Initialize weights and biases\n",
    "    L = len(weights_biases) // 2  # Number of layers\n",
    "\n",
    "    for i in range(iterations):\n",
    "        LNLcaches = forward_prop(weights_biases, X)  # Perform forward propagation\n",
    "        grads = back_prop(LNLcaches, weights_biases, X, Y)  # Compute gradients using backpropagation\n",
    "        weights_biases = update_params(weights_biases, grads, alpha)  # Update parameters\n",
    "\n",
    "        if (i + 1) % 10 == 0:  # Display accuracy every 10 iterations\n",
    "            print(\"Iteration :\", i + 1)\n",
    "            predictions = get_predictions(LNLcaches[\"A\" + str(L)])\n",
    "            print(\"Loss :\",compute_loss(LNLcaches[\"A\" + str(L)], Y))\n",
    "            print(\"Accuracy :\", get_accuracy(predictions, Y))\n",
    "            print()\n",
    "\n",
    "\n",
    "    return weights_biases # Return final trained parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J6kdotG9fFqY",
   "metadata": {
    "id": "J6kdotG9fFqY"
   },
   "source": [
    "# $Train \\ \\ Deep \\ \\ Neural \\ \\ Network \\ \\ Model$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd2a9711-c76e-4bf5-a4b1-cb6cfbdcf8c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd2a9711-c76e-4bf5-a4b1-cb6cfbdcf8c0",
    "outputId": "d000e549-c0cc-4ae6-f8c8-f395989a91bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 10\n",
      "Loss : 2.1801058653637018\n",
      "Accuracy : 0.37955357142857143\n",
      "\n",
      "Iteration : 20\n",
      "Loss : 1.9352726831177358\n",
      "Accuracy : 0.5157440476190476\n",
      "\n",
      "Iteration : 30\n",
      "Loss : 1.5804341841516236\n",
      "Accuracy : 0.5937202380952381\n",
      "\n",
      "Iteration : 40\n",
      "Loss : 1.2380663973247341\n",
      "Accuracy : 0.6699404761904761\n",
      "\n",
      "Iteration : 50\n",
      "Loss : 1.0746356285716252\n",
      "Accuracy : 0.6816071428571429\n",
      "\n",
      "Iteration : 60\n",
      "Loss : 0.861645107630457\n",
      "Accuracy : 0.7580059523809524\n",
      "\n",
      "Iteration : 70\n",
      "Loss : 0.8210260684498235\n",
      "Accuracy : 0.7264285714285714\n",
      "\n",
      "Iteration : 80\n",
      "Loss : 0.704978006310686\n",
      "Accuracy : 0.780625\n",
      "\n",
      "Iteration : 90\n",
      "Loss : 0.6611488908461235\n",
      "Accuracy : 0.7960416666666666\n",
      "\n",
      "Iteration : 100\n",
      "Loss : 0.6382980103243269\n",
      "Accuracy : 0.7934821428571428\n",
      "\n",
      "Iteration : 110\n",
      "Loss : 0.5616565738862888\n",
      "Accuracy : 0.8294642857142858\n",
      "\n",
      "Iteration : 120\n",
      "Loss : 0.5324431180404587\n",
      "Accuracy : 0.8431547619047619\n",
      "\n",
      "Iteration : 130\n",
      "Loss : 0.512344428741353\n",
      "Accuracy : 0.8498214285714286\n",
      "\n",
      "Iteration : 140\n",
      "Loss : 0.4645750389127832\n",
      "Accuracy : 0.86875\n",
      "\n",
      "Iteration : 150\n",
      "Loss : 0.4517115857149142\n",
      "Accuracy : 0.8703571428571428\n",
      "\n",
      "Iteration : 160\n",
      "Loss : 0.45492844097235163\n",
      "Accuracy : 0.8660714285714286\n",
      "\n",
      "Iteration : 170\n",
      "Loss : 0.4171987932282869\n",
      "Accuracy : 0.8830357142857143\n",
      "\n",
      "Iteration : 180\n",
      "Loss : 0.3958521470540679\n",
      "Accuracy : 0.8895535714285714\n",
      "\n",
      "Iteration : 190\n",
      "Loss : 0.38756253160659293\n",
      "Accuracy : 0.8916666666666667\n",
      "\n",
      "Iteration : 200\n",
      "Loss : 0.40239518058597495\n",
      "Accuracy : 0.8846130952380953\n",
      "\n",
      "Iteration : 210\n",
      "Loss : 0.4092693698185956\n",
      "Accuracy : 0.8813095238095238\n",
      "\n",
      "Iteration : 220\n",
      "Loss : 0.3534344159733291\n",
      "Accuracy : 0.902172619047619\n",
      "\n",
      "Iteration : 230\n",
      "Loss : 0.34388691699664276\n",
      "Accuracy : 0.9045833333333333\n",
      "\n",
      "Iteration : 240\n",
      "Loss : 0.3373712608820404\n",
      "Accuracy : 0.9052678571428572\n",
      "\n",
      "Iteration : 250\n",
      "Loss : 0.33757208920867243\n",
      "Accuracy : 0.9047916666666667\n",
      "\n",
      "Iteration : 260\n",
      "Loss : 0.39447742487591214\n",
      "Accuracy : 0.878125\n",
      "\n",
      "Iteration : 270\n",
      "Loss : 0.3260048352922307\n",
      "Accuracy : 0.9088690476190476\n",
      "\n",
      "Iteration : 280\n",
      "Loss : 0.31248266346930703\n",
      "Accuracy : 0.9130357142857143\n",
      "\n",
      "Iteration : 290\n",
      "Loss : 0.3064073567750888\n",
      "Accuracy : 0.9147916666666667\n",
      "\n",
      "Iteration : 300\n",
      "Loss : 0.3008741056822189\n",
      "Accuracy : 0.9164583333333334\n",
      "\n",
      "Iteration : 310\n",
      "Loss : 0.29570969806038344\n",
      "Accuracy : 0.9177380952380952\n",
      "\n",
      "Iteration : 320\n",
      "Loss : 0.29081306540711604\n",
      "Accuracy : 0.9188392857142857\n",
      "\n",
      "Iteration : 330\n",
      "Loss : 0.286138417573754\n",
      "Accuracy : 0.92\n",
      "\n",
      "Iteration : 340\n",
      "Loss : 0.28165027636610623\n",
      "Accuracy : 0.9208928571428572\n",
      "\n",
      "Iteration : 350\n",
      "Loss : 0.2773327946693891\n",
      "Accuracy : 0.9220535714285715\n",
      "\n",
      "Iteration : 360\n",
      "Loss : 0.27315781254394267\n",
      "Accuracy : 0.9234821428571428\n",
      "\n",
      "Iteration : 370\n",
      "Loss : 0.26912392433021837\n",
      "Accuracy : 0.9245238095238095\n",
      "\n",
      "Iteration : 380\n",
      "Loss : 0.26522191932336003\n",
      "Accuracy : 0.9254464285714286\n",
      "\n",
      "Iteration : 390\n",
      "Loss : 0.2615116525401722\n",
      "Accuracy : 0.9266666666666666\n",
      "\n",
      "Iteration : 400\n",
      "Loss : 0.2584255965631906\n",
      "Accuracy : 0.9275297619047619\n",
      "\n",
      "Iteration : 410\n",
      "Loss : 0.25898191389276876\n",
      "Accuracy : 0.9266964285714285\n",
      "\n",
      "Iteration : 420\n",
      "Loss : 0.2829456213126034\n",
      "Accuracy : 0.9175595238095238\n",
      "\n",
      "Iteration : 430\n",
      "Loss : 0.3179584185590293\n",
      "Accuracy : 0.9049404761904762\n",
      "\n",
      "Iteration : 440\n",
      "Loss : 0.24501034863662102\n",
      "Accuracy : 0.9318154761904762\n",
      "\n",
      "Iteration : 450\n",
      "Loss : 0.24123644693539859\n",
      "Accuracy : 0.9326488095238096\n",
      "\n",
      "Iteration : 460\n",
      "Loss : 0.23781386109042887\n",
      "Accuracy : 0.9335714285714286\n",
      "\n",
      "Iteration : 470\n",
      "Loss : 0.2345496308900998\n",
      "Accuracy : 0.9342559523809524\n",
      "\n",
      "Iteration : 480\n",
      "Loss : 0.23140703519942468\n",
      "Accuracy : 0.9350892857142857\n",
      "\n",
      "Iteration : 490\n",
      "Loss : 0.22836585448771704\n",
      "Accuracy : 0.9358928571428572\n",
      "\n",
      "Iteration : 500\n",
      "Loss : 0.22540598842213735\n",
      "Accuracy : 0.9368154761904762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network using gradient descent\n",
    "weights_biases = gradient_descent(X_train, Y_train, 500, 0.1, [784, 100, 30, 20, 10])\n",
    "# X_train: Input data, Y_train: True labels, 1000: Iterations, 0.1: Learning rate, [784, 100, 30, 20, 10]: Layer dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zXKLHP3CflVx",
   "metadata": {
    "id": "zXKLHP3CflVx"
   },
   "source": [
    "# $Accuracy \\ \\ of \\ \\ Trained \\ \\ Model$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14c4659-c8a6-4838-811c-67d0ea144f7b",
   "metadata": {
    "id": "a14c4659-c8a6-4838-811c-67d0ea144f7b"
   },
   "outputs": [],
   "source": [
    "# Make predictions using the trained model\n",
    "def make_predictions(X, weights_biases):\n",
    "    L = len(weights_biases) // 2  # Number of layers in the network\n",
    "    LNLcaches = forward_prop(weights_biases, X)  # Forward propagation\n",
    "    predictions = get_predictions(LNLcaches[\"A\" + str(L)])  # Get predicted labels\n",
    "    return predictions  # Return predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2fc9c63-fd14-4f8e-b08e-31b5209e97df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2fc9c63-fd14-4f8e-b08e-31b5209e97df",
    "outputId": "47c8d024-96c4-46d4-f7ce-2c3b2d40f9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222619047619047\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set and calculate accuracy\n",
    "Y_pred = make_predictions(X_test, weights_biases)  # Generate predictions for the test data\n",
    "accuracy = get_accuracy(Y_pred, Y_test)  # Calculate the accuracy by comparing predictions with true labels\n",
    "print(accuracy)  # Print the accuracy of the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T46nqxmBf0JM",
   "metadata": {
    "id": "T46nqxmBf0JM"
   },
   "source": [
    "# $Make \\ \\ Predictions \\ \\ on \\ \\ Unseen \\ \\ Data$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d08a5f9a-7245-4d19-94fa-593ac0bd8fcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "d08a5f9a-7245-4d19-94fa-593ac0bd8fcc",
    "outputId": "d206f7ce-ee1f-48f2-c689-4ce7d0f2d416"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and display the first few rows of unseen test data\n",
    "unseen_data = pd.read_csv(\"test.csv\")  # Read the unseen test data from CSV\n",
    "unseen_data.head()  # Display the first 5 rows of the unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73d6feeb-ada8-4e03-8725-faed3b4775b4",
   "metadata": {
    "id": "73d6feeb-ada8-4e03-8725-faed3b4775b4"
   },
   "outputs": [],
   "source": [
    "# Function to identify an image from the unseen dataset using the trained model\n",
    "def identify(weights_biases=weights_biases, unseen_data=unseen_data):\n",
    "    unseen_data = np.array(unseen_data)  # Convert the unseen data to a numpy array\n",
    "    r = np.random.randint(0, unseen_data.shape[0]-1)  # Randomly select an index from unseen data\n",
    "    x = unseen_data[r].reshape(-1, 1)  # Reshape the selected image to column vector\n",
    "    x = x / 255  # Normalize the image\n",
    "\n",
    "    # Reshape image for visualization and display it\n",
    "    current_image = x.reshape((28, 28)) * 255  # Reshape back to 28x28 for visualization\n",
    "    plt.gray()  # Set the color map to grayscale\n",
    "    plt.imshow(current_image, interpolation='nearest')  # Display the image\n",
    "    plt.show()  # Show the image\n",
    "\n",
    "    # Make and print the prediction\n",
    "    print(\"This is :\", make_predictions(x, weights_biases)[0])  # Output predicted class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b0cc4bc-128e-418e-ae60-1c514bdc4f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "4b0cc4bc-128e-418e-ae60-1c514bdc4f01",
    "outputId": "f6f11152-dbb6-4384-ea7a-b176eaa08e13"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is : 3\n"
     ]
    }
   ],
   "source": [
    "# Call the identify function to randomly select an image from the unseen dataset and make a prediction\n",
    "identify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d6914-72c6-4757-866f-e4ac0077cd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
